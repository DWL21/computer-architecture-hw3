# RISC-V Simulator A 벤치마크 최적화 리포트

## 📋 프로젝트 개요

### 시뮬레이터 구조
- **아키텍처**: RISC-V 64비트 파이프라인 시뮬레이터
- **파이프라인**: 5단계 (Fetch → Decode → Execute → Memory → WriteBack)
- **캐시 시스템**: 계층형 L1/L2 캐시
- **분기 예측**: 4가지 전략 지원 (AT, NT, BTFNT, BPB)

### A 벤치마크 분석
- **알고리즘**: 35×35 행렬 곱셈 (Matrix Multiplication)
- **특성**: 메모리 집약적 워크로드
- **연산량**: O(n³) = 42,875 곱셈 연산
- **메모리 패턴**: 순차적 및 스트라이드 접근

```c
void func_A(int a[][SIZE], int b[][SIZE], int c[][SIZE]) {
    for (i = 0; i < SIZE; i++)
        for (j = 0; j < SIZE; j++)
            for (k = 0; k < SIZE; k++)
                c[i][j] += a[i][k] * b[k][j];
}
```

## 🚀 최적화 과정

### 1단계: 초기 상태 분석
**원본 설정 (configA)**:
```
l1.cacheSize=256
l1.blockSize=32
l1.associativity=2
l2.cacheSize=2048
l2.blockSize=32
l2.associativity=4
bp=BPB
```

**초기 성능**:
- Benchmark Score: **0.7874**
- 사이클 수: 10,966,175
- CPI: 2.5984
- L1 Cache 미스: 849,272 B

### 2단계: 최적화 전략 수립
행렬 곱셈의 메모리 접근 패턴을 고려한 최적화 방향:

1. **캐시 크기 확대**: 더 많은 데이터를 캐시에 유지
2. **블록 크기 조정**: 공간 지역성 활용 극대화
3. **연관도 최적화**: 패널티와 성능의 균형점 찾기
4. **L2 캐시 강화**: L1 미스 시 빠른 L2 히트 보장

### 3단계: 점진적 최적화

#### 시도 1: 기본 최적화
```
l1.cacheSize=512    (+100%)
l1.blockSize=16     (-50%)
l1.associativity=1  (-50%)
l2.cacheSize=4096   (+100%)
```
**결과**: 0.7680 (성능 저하)

#### 시도 2: 캐시 크기 확대
```
l1.cacheSize=1024   (+300%)
l1.blockSize=64     (+100%)
l1.associativity=1  (-50%)
l2.cacheSize=8192   (+300%)
```
**결과**: 0.7874 (원점 회귀, 사이클 감소)

#### 시도 3: 최적 설정 발견 ✅
```
l1.cacheSize=2048   (+700%)
l1.blockSize=64     (+100%)
l1.associativity=2  (유지)
l2.cacheSize=16384  (+700%)
l2.blockSize=64     (+100%)
l2.associativity=2  (-50%)
```
**결과**: 0.9744 (성능 대폭 향상!)

#### 시도 4: 과최적화 검증
```
l1.cacheSize=4096   (더 확대)
l1.blockSize=128    (더 확대)
```
**결과**: 0.8170 (성능 저하 - 블록 크기 패널티)

## 📊 최종 성능 비교

### 최적화된 설정
```
configA
l1.cacheSize=2048
l1.blockSize=64
l1.associativity=2
l2.cacheSize=16384
l2.blockSize=64
l2.associativity=2
bp=BPB
```

### 성능 향상 결과

| 성능 지표 | 원래 값 | 최적화 후 | 개선율 |
|-----------|---------|-----------|--------|
| **🏆 Benchmark Score** | **0.7874** | **0.9744** | **+23.7%** |
| 총 사이클 수 | 10,966,175 | 6,907,164 | **-37.0%** |
| CPI (Cycles per Instruction) | 2.5984 | 1.6366 | **-37.0%** |
| 평균 명령어 처리율 | 0.3849 IPC | 0.6109 IPC | **+58.7%** |

### 캐시 성능 향상

#### L1 캐시
| 지표 | 원래 값 | 최적화 후 | 개선율 |
|------|---------|-----------|--------|
| 총 읽기 | 28,234,392 B | 28,234,392 B | 동일 |
| 총 쓰기 | 4,568,876 B | 4,568,876 B | 동일 |
| 히트 바이트 | 31,953,996 B | 32,681,407 B | **+2.3%** |
| **미스 바이트** | **849,272 B** | **121,861 B** | **-85.6%** |

#### L2 캐시
| 지표 | 원래 값 | 최적화 후 | 개선율 |
|------|---------|-----------|--------|
| 총 읽기 | 27,176,704 B | 7,799,104 B | **-71.3%** |
| 총 쓰기 | 6,274,368 B | 4,596,864 B | **-26.7%** |
| 히트 바이트 | 33,293,688 B | 12,328,546 B | -62.9% |
| **미스 바이트** | **157,384 B** | **67,422 B** | **-57.2%** |

### 파이프라인 효율성
- **Control Hazards**: 193,337 (변화 없음)
- **Data Hazards**: 3,241,017 (변화 없음)  
- **Memory Hazards**: 655,588 (변화 없음)
- **Branch Prediction Accuracy**: 74.04% (변화 없음)

## 💡 핵심 인사이트

### 1. 캐시 크기의 임계점
- L1: 256B → 2048B (8배 증가)로 극적인 성능 향상
- L2: 2048B → 16384B (8배 증가)로 L1 미스 커버

### 2. 블록 크기 최적화
- 32B → 64B: 행렬 데이터의 공간 지역성 활용 극대화
- 128B 이상: 패널티 함수로 인한 성능 저하

### 3. 연관도 균형점
- L1: 2-way 유지 (충분한 성능)
- L2: 4-way → 2-way (패널티 감소 효과)

### 4. 메모리 계층 구조 효과
- L1 미스률 85.6% 감소 → L2 접근 대폭 감소
- 메모리 계층 구조의 시너지 효과 극대화

## 🎯 결론

### 주요 성과
1. **벤치마크 스코어 23.7% 향상** (0.7874 → 0.9744)
2. **실행 사이클 37% 감소** (1,096만 → 691만 사이클)
3. **L1 캐시 미스 85.6% 감소** (효율적인 메모리 활용)

### 최적화 요인
- **캐시 크기 확대**: 워킹셋을 충분히 수용
- **블록 크기 조정**: 공간 지역성 극대화  
- **메모리 계층 설계**: L1-L2 캐시 시너지 효과

### 활용 가치
이 최적화 결과는 **메모리 집약적 워크로드**에 대한 캐시 시스템 설계 가이드라인을 제시하며, 특히 **과학 계산 및 행렬 연산** 중심의 애플리케이션 성능 향상에 직접 적용 가능합니다.

---

*최적화 완료일: 2024년*  
*시뮬레이터: RISC-V Simulator v1.0*  
*벤치마크: Matrix Multiplication (35×35)* 